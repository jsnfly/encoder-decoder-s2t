{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204623fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f55966",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/cv_8_0_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21933b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(fp16=True)\n",
    "print(f'Using {accelerator.device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d7525",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Encoder Output Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c6871",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model, HubertModel\n",
    "from wav2vec_feature_extraction import extract_features_to_files\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from cv8_en import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cb8ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = DATA_PATH / \"encoder_outputs\"\n",
    "SAMPLING_RATE = 16_000\n",
    "SEED = 419\n",
    "USE_TRAIN_PCT = 0.35\n",
    "USE_VAL_PCT = 0.25\n",
    "ENCODER_MDL = 'facebook/hubert-xlarge-ls960-ft'\n",
    "BATCH_SIZE = 6\n",
    "MAX_AUDIO_LENGTH = 300_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a561be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not OUTPUT_PATH.exists():\n",
    "    train, uncommon_chars = prepare('train', USE_TRAIN_PCT, SAMPLING_RATE, SEED)\n",
    "    val, _ = prepare('validation', USE_VAL_PCT, SAMPLING_RATE, SEED, uncommon_chars)\n",
    "\n",
    "    # Load model and feature extractor.\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(ENCODER_MDL)\n",
    "    mdl = HubertModel.from_pretrained(ENCODER_MDL) # Wav2Vec2Model.from_pretrained(ENCODER_MDL)\n",
    "    mdl.eval().to(accelerator.device)\n",
    "\n",
    "    # Write model outputs to files.\n",
    "    extract_features_to_files(mdl, feature_extractor, train, BATCH_SIZE, OUTPUT_PATH / 'train', \n",
    "                              MAX_AUDIO_LENGTH, SAMPLING_RATE)\n",
    "\n",
    "    extract_features_to_files(mdl, feature_extractor, val, BATCH_SIZE, OUTPUT_PATH / 'val', \n",
    "                              MAX_AUDIO_LENGTH, SAMPLING_RATE)\n",
    "    \n",
    "    # Clear GPU.\n",
    "    mdl.cpu()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbe2c9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary to disable warnings.\n",
    "%env TOKENIZERS_PARALLELISM=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29637dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from data_loading import Wav2VecFeaturesDataset, make_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import Wav2Vec2BaseModelOutput\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.wav2vec_gpt2 import Wav2VecGPT2Model\n",
    "from wer import calculate_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path('./results/1')\n",
    "LOG_PATH = OUTPUT_PATH / 'logs'\n",
    "\n",
    "ENCODER_ID = 'facebook/hubert-xlarge-ls960-ft'\n",
    "DECODER_ID = 'gpt2'\n",
    "PROMPT = 'Transcription:'\n",
    "PAD_TOKEN = '_'\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATES = {\n",
    "    'default': 1e-6,\n",
    "    ('cross_attn', 'crossattention', 'enc_to_dec_proj', 'encoder_outputs_pos_emb'): 6e-4\n",
    "}\n",
    "LR_SCHEDULER = lr_scheduler.CosineAnnealingLR\n",
    "MAX_EPOCHS = 3\n",
    "ACCUMULATE_GRAD = 2\n",
    "MAX_LEN = 39\n",
    "\n",
    "def LR_SCHEDULER(optimizer):\n",
    "    num_steps = MAX_EPOCHS * (len(train_ds) // (BATCH_SIZE * ACCUMULATE_GRAD)) * 1.5\n",
    "    return lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(DECODER_ID)\n",
    "tokenizer.add_special_tokens({'pad_token': PAD_TOKEN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10042eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = make_collate_fn(tokenizer)\n",
    "\n",
    "train_ds = Wav2VecFeaturesDataset(DATA_PATH / 'encoder_outputs/train', PROMPT)\n",
    "train_dl = DataLoader(train_ds, BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "val_ds = Wav2VecFeaturesDataset(DATA_PATH / 'encoder_outputs/val', PROMPT)\n",
    "val_dl = DataLoader(val_ds, BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2VecGPT2Model.from_encoder_decoder_pretrained(ENCODER_ID, DECODER_ID)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91431444",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_groups = []\n",
    "\n",
    "assigned_modules = []\n",
    "for modules, lr in LEARNING_RATES.items():\n",
    "    if isinstance(modules, tuple):\n",
    "        module_names, module_params = zip(\n",
    "            *[(n,p) for n,p in model.named_parameters() if any(m in n for m in modules)]\n",
    "        )\n",
    "        assigned_modules += module_names\n",
    "        optimizer_groups.append({'params': module_params, 'lr': lr})\n",
    "        \n",
    "optimizer_groups.append({\n",
    "    'params': [p for n,p in model.named_parameters() if not n in assigned_modules],\n",
    "    'lr': LEARNING_RATES['default']\n",
    "})\n",
    "\n",
    "optimizer = AdamW(optimizer_groups, weight_decay=0.0)\n",
    "lr_scheduler = LR_SCHEDULER(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8135f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, optimizer, train_dl, val_dl = accelerator.prepare(model, optimizer, train_dl, val_dl)\n",
    "model.encoder.cpu()  # Does not need to be on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6b859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(LOG_PATH)\n",
    "val_golds = [eg['sentence'][len(PROMPT) + 1:] for eg in val_ds]\n",
    "global_train_step, val_count = 0, 0\n",
    "prompt_token_count = len(tokenizer(PROMPT).input_ids)\n",
    "best_wer = 10.\n",
    "\n",
    "def evaluate():\n",
    "    global val_count, best_wer\n",
    "    \n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    for encoder_hidden_states, _, input_ids in val_dl:\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(\n",
    "                decoder_input_ids=input_ids[:, :prompt_token_count],\n",
    "                encoder_outputs=Wav2Vec2BaseModelOutput(encoder_hidden_states), \n",
    "                max_length=MAX_LEN\n",
    "            )\n",
    "        val_preds += tokenizer.batch_decode(generated)\n",
    "    val_preds = [pred[len(PROMPT) + 1:].rstrip(PAD_TOKEN) for pred in val_preds]\n",
    "    wer = calculate_wer(val_preds, val_golds)\n",
    "    writer.add_scalar('val_wer', wer, val_count)\n",
    "    print('WER: ', wer)\n",
    "\n",
    "    if wer < best_wer:\n",
    "        best_wer = wer\n",
    "        model.save_pretrained(OUTPUT_PATH)\n",
    "        print('Saved new best model.')\n",
    "    val_count += 1\n",
    "    return val_preds\n",
    "\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    model.train()\n",
    "    for encoder_hidden_states, _, input_ids in train_dl:\n",
    "        global_train_step += 1\n",
    "        out = model(decoder_input_ids=input_ids[:, :-1], \n",
    "                    labels=input_ids[:, 1:].contiguous(), \n",
    "                    encoder_outputs=Wav2Vec2BaseModelOutput(encoder_hidden_states))\n",
    "        accelerator.backward(out.loss)\n",
    "        writer.add_scalar('train_loss', out.loss.item(), global_train_step)\n",
    "        [writer.add_scalar(f'learning_rate_group{i}', group['lr'], global_train_step) \n",
    "         for i, group in enumerate(optimizer.param_groups)]\n",
    "        \n",
    "        if (global_train_step + 1) % ACCUMULATE_GRAD == 0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        if global_train_step % 20 == 0:\n",
    "            print(out.loss.item())\n",
    "        \n",
    "        if global_train_step % 5000 == 0:\n",
    "            val_preds = evaluate()\n",
    "            model.train()\n",
    "            \n",
    "# Final evaluation.\n",
    "val_preds = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_golds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./train.ipynb {LOG_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
